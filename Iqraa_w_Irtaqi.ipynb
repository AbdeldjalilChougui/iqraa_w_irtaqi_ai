{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8643,
          "sourceType": "datasetVersion",
          "datasetId": 1802
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import plotly\n",
        "plotly.offline.init_notebook_mode(connected=True)\n",
        "\n",
        "#Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-07-21T21:37:46.977076Z",
          "iopub.execute_input": "2023-07-21T21:37:46.977512Z",
          "iopub.status.idle": "2023-07-21T21:37:49.111344Z",
          "shell.execute_reply.started": "2023-07-21T21:37:46.977477Z",
          "shell.execute_reply": "2023-07-21T21:37:49.110445Z"
        },
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "_AvIOTDSNF48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau"
      ],
      "metadata": {
        "_kg_hide-output": false,
        "execution": {
          "iopub.status.busy": "2023-07-21T22:03:00.369217Z",
          "iopub.execute_input": "2023-07-21T22:03:00.370097Z",
          "iopub.status.idle": "2023-07-21T22:03:10.101194Z",
          "shell.execute_reply.started": "2023-07-21T22:03:00.370057Z",
          "shell.execute_reply": "2023-07-21T22:03:10.100001Z"
        },
        "trusted": true,
        "id": "re7FpSjRNF4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(AUDIO_PATH):\n",
        "    audio, sr = librosa.load(AUDIO_PATH)\n",
        "    return audio, sr\n",
        "\n",
        "def wav2melSpec(AUDIO_PATH):\n",
        "    audio, sr = librosa.load(AUDIO_PATH)\n",
        "    return librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "\n",
        "def imgSpec(ms_feature):\n",
        "    fig, ax = plt.subplots()\n",
        "    ms_dB = librosa.power_to_db(ms_feature, ref=np.max)\n",
        "    print(ms_feature.shape)\n",
        "    img = librosa.display.specshow(ms_dB, x_axis='time', y_axis='mel', ax=ax)\n",
        "    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "    ax.set(title='Mel-frequency spectrogram');\n",
        "\n",
        "def hear_audio(AUDIO_PATH):\n",
        "    audio, sr = librosa.load(AUDIO_PATH)\n",
        "    print(\"\\t\", end=\"\")\n",
        "    ipd.display(ipd.Audio(data=audio, rate=sr))\n",
        "\n",
        "\n",
        "def get_audio_info(path, show_melspec=False, label=None):\n",
        "    spec = wav2melSpec(path)\n",
        "    if label is not None:\n",
        "        print(\"Label:\", label)\n",
        "    if show_melspec is not False:\n",
        "        imgSpec(spec)\n",
        "    hear_audio(path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T22:04:02.646679Z",
          "iopub.execute_input": "2023-07-21T22:04:02.647558Z",
          "iopub.status.idle": "2023-07-21T22:04:02.659052Z",
          "shell.execute_reply.started": "2023-07-21T22:04:02.647516Z",
          "shell.execute_reply": "2023-07-21T22:04:02.657855Z"
        },
        "trusted": true,
        "id": "BGQXnaTiNF4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextTransform:\n",
        "    def __init__(self):\n",
        "        self.char_to_num_dict =  {\n",
        "      \"а\": 1, \"б\": 2, \"в\": 3, \"г\": 4, \"д\": 5, \"е\": 6, \"ё\": 7, \"ж\": 8, \"з\": 9, \"и\": 10, \"й\": 11,\n",
        "      \"к\": 12, \"л\": 13, \"м\": 14, \"н\": 15, \"о\": 16, \"п\": 17, \"р\": 18, \"с\": 19, \"т\": 20, \"у\": 21,\n",
        "      \"ф\": 22, \"х\": 23, \"ц\": 24, \"ч\": 25, \"ш\": 26, \"щ\": 27, \"ь\": 28, \"ы\": 29, \"ъ\": 30, \"э\": 31,\n",
        "      \"ю\": 32, \"я\": 33, \" \": 34}\n",
        "\n",
        "        self.index_map = {}\n",
        "        for key, value in self.char_to_num_dict.items():\n",
        "            self.index_map[value] = key\n",
        "\n",
        "    def char_to_num(self, sentence):\n",
        "        num_sent = np.zeros(5000)\n",
        "        i = 0\n",
        "        for char in sentence.lower():\n",
        "            if char in self.char_to_num_dict.keys():\n",
        "                num_sent[i]=self.char_to_num_dict[char]\n",
        "            i += 1\n",
        "        return num_sent\n",
        "\n",
        "    def num_to_char(self, sentence):\n",
        "        char_sent = np.array()\n",
        "        i = 0\n",
        "        for num in sentence:\n",
        "            char_sent[i]=self.index_map[num]\n",
        "            i += 1\n",
        "        return char_sent"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T22:15:06.767291Z",
          "iopub.execute_input": "2023-07-21T22:15:06.767698Z",
          "iopub.status.idle": "2023-07-21T22:15:06.779838Z",
          "shell.execute_reply.started": "2023-07-21T22:15:06.767665Z",
          "shell.execute_reply": "2023-07-21T22:15:06.778652Z"
        },
        "trusted": true,
        "id": "dru_Z6MwNF5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = TextTransform()\n",
        "\n",
        "labels = []\n",
        "for label in labels_uniq:\n",
        "    labels.append(label)\n",
        "    labels.append(label)\n",
        "\n",
        "labels = list(map(text_transform.char_to_num, labels))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T22:54:00.462953Z",
          "iopub.execute_input": "2023-07-21T22:54:00.463454Z",
          "iopub.status.idle": "2023-07-21T22:54:00.547804Z",
          "shell.execute_reply.started": "2023-07-21T22:54:00.463415Z",
          "shell.execute_reply": "2023-07-21T22:54:00.546707Z"
        },
        "trusted": true,
        "id": "Kx1XGkwcNF5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MFCC coefficients\n",
        "\n"
      ],
      "metadata": {
        "id": "OksuwNimNF5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ConfigParser\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from pprint import pprint\n",
        "\n",
        "class cnnlib:\n",
        "\tdef __init__(self):\n",
        "\t\tself.configParser = ConfigParser.RawConfigParser()\n",
        "\t\tself.configFilePath = r'../config/model.conf'\n",
        "\t\tself.configParser.read(self.configFilePath)\n",
        "\t\tself.channel = 1\n",
        "\n",
        "\t\tself.surah = int(self.configParser.get(\"ml-config\",\"surah\"))\n",
        "\t\tself.total_ayah = int(self.configParser.get(\"ml-config\",\"total_ayah\"))\n",
        "\n",
        "\t\tself.model = load_model(\"../generatedmodel/surah-\"+str(self.surah)+\"-model.h5\",custom_objects={\"f1\": self.f1, \"precision\": self.precision})\n",
        "\n",
        "\tdef wav2mfcc(self, file_path):\n",
        "\t\tmax_pad_len=int(self.configParser.get(\"ml-config\", \"max_pad_len\"))\n",
        "\n",
        "\t\ty, sr = librosa.load(file_path)\n",
        "\t\ty = librosa.effects.harmonic(y)\n",
        "\t\tmfcc = librosa.feature.tonnetz(y=y, sr=sr) #this is tonnetz, but i'm too lazy to change\n",
        "\n",
        "\t\tpad_width = max_pad_len - mfcc.shape[1]\n",
        "\t\tmfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\t\treturn mfcc\n",
        "\n",
        "\t# Metrics\n",
        "\t## https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\tdef precision(self, y_true, y_pred):\n",
        "        \ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        \tpredicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        \treturn true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "\tdef recall(self,y_true, y_pred):\n",
        "        \ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        \tpossible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        \treturn true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "\tdef f1(self, y_true, y_pred):\n",
        "        \tp = self.precision(y_true, y_pred)\n",
        "        \tr = self.recall(y_true, y_pred)\n",
        "        \treturn 2*((p*r)/(p+r+K.epsilon()))\n",
        "\n",
        "\tdef get_labels(self):\n",
        "\t\tlabels = []\n",
        "\t\tfor i in range(1, self.total_ayah+1):\n",
        "\t\t\tlabels.append(\"ayat-\"+str(i))\n",
        "\n",
        "\t\tlabel_indices = np.arange(0, len(labels))\n",
        "\t\treturn labels, label_indices, to_categorical(label_indices)\n",
        "\n",
        "\tdef isCorrect(self, location, label):\n",
        "\t\tprint \"Loading \"+location+\" ...\"\n",
        "\t\tsample = self.wav2mfcc(location)\n",
        "\t\tsample_reshaped = sample.reshape(1, int(self.configParser.get(\"ml-config\",\"shape_1\")), int(self.configParser.get(\"ml-config\",\"shape_2\")), self.channel)\n",
        "\t\tanswer = self.get_labels()[0][np.argmax(self.model.predict(sample_reshaped))]\n",
        "\n",
        "\t\tprint(\"[DEBUG] Predicted label: \"+answer+\". Actual Label: ayat-\"+label)\n",
        "\t\tif (answer == \"ayat-\"+label):\n",
        "\t\t\treturn True\n",
        "\t\telse:\n",
        "\t\t\treturn False\n",
        "\n",
        "\tdef test(self):\n",
        "\t\tfor i in range(1,self.total_ayah+1):\n",
        "\t\t\tsample = self.wav2mfcc(\"../testing/\"+str(self.surah)+\"/\"+str(i)+\".wav\")\n",
        "        \t\tsample_reshaped = sample.reshape(1, int(self.configParser.get(\"ml-config\",\"shape_1\")), int(self.configParser.get(\"ml-config\",\"shape_2\")), self.channel)\n",
        "\t\t\tanswer = self.get_labels()[0][np.argmax(self.model.predict(sample_reshaped))]\n",
        "       \t\t\tprint(\"Predicted label: \"+answer+\". Actual Label: ayat-\"+str(i))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T22:17:55.370946Z",
          "iopub.execute_input": "2023-07-21T22:17:55.371378Z",
          "iopub.status.idle": "2023-07-21T22:17:55.380482Z",
          "shell.execute_reply.started": "2023-07-21T22:17:55.371341Z",
          "shell.execute_reply": "2023-07-21T22:17:55.379113Z"
        },
        "trusted": true,
        "id": "WWwvAA6wNF5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train test split\n",
        "\n"
      ],
      "metadata": {
        "id": "-NZBzytQNF5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cut_array(text_arr):\n",
        "    return text_arr[:1756]\n",
        "\n",
        "border = 3800\n",
        "\n",
        "audio_train, text_train, audio_test, text_test = np.array(mfcc_spectograms[:3800]), np.array(list(map(cut_array, labels[:3800]))), np.array(mfcc_spectograms[3800:]), np.array(list(map(cut_array,labels[3800:])))\n",
        "print(text_train.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:29.661735Z",
          "iopub.execute_input": "2023-07-21T23:31:29.662252Z",
          "iopub.status.idle": "2023-07-21T23:31:30.03823Z",
          "shell.execute_reply.started": "2023-07-21T23:31:29.662201Z",
          "shell.execute_reply": "2023-07-21T23:31:30.036864Z"
        },
        "trusted": true,
        "id": "1k9alsOXNF5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build a CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "ZThWs1_INF5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dropout = 0.15\n",
        "input_dim = (14, 2000,1)\n",
        "output_dim_vocab = 34\n",
        "output_dim = 1756\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Conv2D(filters=32, kernel_size=[6, 6], strides=[2, 2],input_shape=input_dim, padding=\"same\", use_bias=False),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Activation(activation='leaky_relu'),\n",
        "  layers.MaxPooling2D(pool_size=(3,3)),\n",
        "  layers.Dropout(dropout),\n",
        "  # 2 layer\n",
        "  layers.Conv2D(128,(3,3),padding='same'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Activation(activation='relu'),\n",
        "#   layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(dropout),\n",
        "  # 3 conv layer\n",
        "  layers.Conv2D(512,(3,3),padding='same'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Activation(activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(dropout),\n",
        "  # 4 conv layer\n",
        "  layers.Conv2D(512,(3,3),padding='same'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Activation(activation='relu'),\n",
        "#   layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(dropout),\n",
        "  layers.Dense(512),\n",
        "  layers.Activation(activation='leaky_relu'),\n",
        "  layers.Dropout(dropout),\n",
        "  layers.Conv2D(filters=32, kernel_size=[6, 6], strides=[1, 1], padding=\"same\", use_bias=False),\n",
        "#   fully cpnnected layer with 256 nuerons\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"softmax\"),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Dropout(dropout),\n",
        "  layers.Activation(activation='relu'),\n",
        "#   fully cpnnected layer with 512 nuerons\n",
        "  layers.Dense(output_dim_vocab, activation=\"softmax\"),\n",
        "  layers.Dense(512, activation=\"softmax\"),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Dropout(dropout),\n",
        "  layers.Activation(activation='relu'),\n",
        "#     output layer\n",
        "  layers.Dense(output_dim, activation=\"softmax\"),\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:35.267695Z",
          "iopub.execute_input": "2023-07-21T23:31:35.268222Z",
          "iopub.status.idle": "2023-07-21T23:31:35.68436Z",
          "shell.execute_reply.started": "2023-07-21T23:31:35.268155Z",
          "shell.execute_reply": "2023-07-21T23:31:35.683155Z"
        },
        "trusted": true,
        "id": "IfME2_RINF5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CTC Loss Function\n",
        "\n"
      ],
      "metadata": {
        "id": "Tqq_PhAgNF5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0],dtype = 'int64')\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1],dtype = 'int64')\n",
        "    label_length = tf.cast(tf.shape(y_true)[1],dtype = 'int64')\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype = 'int64')\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype = 'int64')\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:41.207134Z",
          "iopub.execute_input": "2023-07-21T23:31:41.20775Z",
          "iopub.status.idle": "2023-07-21T23:31:41.217116Z",
          "shell.execute_reply.started": "2023-07-21T23:31:41.207701Z",
          "shell.execute_reply": "2023-07-21T23:31:41.21559Z"
        },
        "trusted": true,
        "id": "KRZDqLtYNF5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "#     loss=CTCLoss,\n",
        "#     metrics=[CERMetric(), WERMetric()],\n",
        "#     metrics=EditDistance())\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:46.696931Z",
          "iopub.execute_input": "2023-07-21T23:31:46.69743Z",
          "iopub.status.idle": "2023-07-21T23:31:46.713869Z",
          "shell.execute_reply.started": "2023-07-21T23:31:46.697388Z",
          "shell.execute_reply": "2023-07-21T23:31:46.712519Z"
        },
        "trusted": true,
        "id": "1cqZw01XNF5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define callbacks\n",
        "model_path = 'Arabic_speech_model'\n",
        "\n",
        "earlystopper = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')\n",
        "checkpoint = ModelCheckpoint(f\"{model_path}/model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "tb_callback = TensorBoard(f'{model_path}/logs', update_freq=1)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, min_delta=1e-10, patience=3, verbose=1, mode='auto')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:51.820453Z",
          "iopub.execute_input": "2023-07-21T23:31:51.820931Z",
          "iopub.status.idle": "2023-07-21T23:31:51.828557Z",
          "shell.execute_reply.started": "2023-07-21T23:31:51.820894Z",
          "shell.execute_reply": "2023-07-21T23:31:51.827349Z"
        },
        "trusted": true,
        "id": "QmqK9L6rNF5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:31:57.23552Z",
          "iopub.execute_input": "2023-07-21T23:31:57.235996Z",
          "iopub.status.idle": "2023-07-21T23:31:57.331644Z",
          "shell.execute_reply.started": "2023-07-21T23:31:57.235959Z",
          "shell.execute_reply": "2023-07-21T23:31:57.330509Z"
        },
        "trusted": true,
        "id": "wv1imEhANF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=audio_train,\n",
        "    y=text_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5, #Original is 50\n",
        "    batch_size=26,\n",
        "    callbacks=[earlystopper, checkpoint, reduceLROnPlat, tb_callback]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-21T23:32:05.507449Z",
          "iopub.execute_input": "2023-07-21T23:32:05.507948Z",
          "iopub.status.idle": "2023-07-21T23:32:05.989348Z",
          "shell.execute_reply.started": "2023-07-21T23:32:05.507909Z",
          "shell.execute_reply": "2023-07-21T23:32:05.987678Z"
        },
        "trusted": true,
        "id": "fSK1KMEvNF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#History  Save to the next time since I could fix my error above."
      ],
      "metadata": {
        "id": "GibEfr4gNF5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# ________________ Graph 1 -------------------------\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# ________________ Graph 2 -------------------------\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Categorical crossentropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ozZHgXpNF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(audio_test, text_test)"
      ],
      "metadata": {
        "id": "5fN0VBANNF5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predict = model.predict(audio_test)\n",
        "print(predict)"
      ],
      "metadata": {
        "id": "6rOcf-DMNF5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}